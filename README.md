# AIPAT
Artificial Intelligence Political Affiliation Test (AIPAT)

*** This project is currently in alpha stage and part of an ongoing R&D project. ***

Welcome to the AIPAT project! Our goal is to provide a transparent assessment of the political biases present in artificial intelligence LLM models. We believe that it is important for AI systems to be unbiased and fair, and when they are not, they should at least say so!

We want to emphasize that our intention is not to start political debates or discussions, but rather to promote transparency and objectivity in AI development. We understand that politics can be a sensitive topic, but we believe that it is essential to uncover any potential biases in order to ensure that AI systems are serving all people equally.
It can also help people decide which models are closer to their personal beliefs and own afiliation. 
(Spoiler-alert: There are clear differences)

Thank you for your interest in the AIPAT project! We appreciate your support and look forward to working together to create a more transparent future for AI.


FAQ:

Q: Will you publicly release the testing method and questions?

A: No, we will not publicly release the testing method and questions. While we recognize the importance of transparency and openness in scientific research, we also need to protect our intellectual property and maintain the integrity of our work. By keeping our testing method and questions private, we can ensure that our results are accurate and reliable, and that they cannot be easily replicated or bypassed by other researchers or organizations.

However, we are committed to making our findings accessible to the public and to the broader community of AI and Data Science professionals. We encourage others to replicate our findings and contribute to our ongoing efforts to evaluate the political biases present in AI models. We are always open to more crowdsourced data and feedback from the community, and we welcome collaboration with other researchers and organizations.

As a commercial company operating in the AI and Data Science space, we believe that it is important to strike a balance between protecting our intellectual property and promoting transparency and accountability in our work. We are confident that our approach will allow us to continue to produce high-quality, reliable, and trustworthy results while maintaining the confidentiality of our testing methods and questions.
